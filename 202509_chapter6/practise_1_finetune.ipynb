{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691c0eec",
   "metadata": {},
   "source": [
    "# 大语言模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fc1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:7893\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置代理\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7893'\n",
    "os.environ['no_proxy'] = '127.0.0.1,localhost'\n",
    "os.environ['NO_PROXY'] = '127.0.0.1,localhost'\n",
    "\n",
    "# 验证\n",
    "print(os.environ.get('http_proxy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05faec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# 使用你的 token 登录\n",
    "login()\n",
    "print(\"Successfully logged in to Hugging Face!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cc75a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-7B-Chat:\n",
      "- tokenization_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Mistral Chat Template:\n",
      "==================================================\n",
      "<s> [INST] You are a helpful assistant.\n",
      "\n",
      "Hello! [/INST]\n",
      "\n",
      "==================================================\n",
      "Qwen Chat Template (手动格式化):\n",
      "==================================================\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hello!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "==================================================\n",
      "SmolLM Chat Template:\n",
      "==================================================\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hello!<|im_end|>\n",
      "\n",
      "\n",
      "==================================================\n",
      "检查各个 tokenizer 是否有 chat_template:\n",
      "==================================================\n",
      "Mistral has chat_template: True\n",
      "Qwen has chat_template: False\n",
      "SmolLM has chat_template: True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 使用你原来的模型\n",
    "# Mistral 需要 token（通过上面的 login 已经提供）\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Qwen 需要 trust_remote_code=True 参数\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-7B-Chat\", trust_remote_code=True)\n",
    "\n",
    "# SmolLM 是开放模型\n",
    "smol_tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Mistral Chat Template:\")\n",
    "print(\"=\" * 50)\n",
    "mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(mistral_chat)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Qwen Chat Template (手动格式化):\")\n",
    "print(\"=\" * 50)\n",
    "# Qwen 使用特殊的格式，不使用 chat template\n",
    "# 格式：<|im_start|>system\\n{content}<|im_end|>\\n<|im_start|>user\\n{content}<|im_end|>\\n<|im_start|>assistant\\n\n",
    "qwen_chat = \"\"\n",
    "for message in messages:\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    qwen_chat += f\"<|im_start|>{role}\\n{content}<|im_end|>\\n\"\n",
    "qwen_chat += \"<|im_start|>assistant\\n\"\n",
    "print(qwen_chat)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SmolLM Chat Template:\")\n",
    "print(\"=\" * 50)\n",
    "smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(smol_chat)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"检查各个 tokenizer 是否有 chat_template:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mistral has chat_template: {mistral_tokenizer.chat_template is not None}\")\n",
    "print(f\"Qwen has chat_template: {qwen_tokenizer.chat_template is not None}\")\n",
    "print(f\"SmolLM has chat_template: {smol_tokenizer.chat_template is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9695e4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral格式：\n",
      "<s> [INST] What's 123 * 456? [/INST] 123 * 456 = 56,088</s>\n",
      "\n",
      "SmolLM格式：\n",
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "What's 123 * 456?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "123 * 456 = 56,088<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试工具调用 - 只有支持的模型才能处理 tool 角色\n",
    "messages_with_tools = [\n",
    "    {\"role\": \"user\", \"content\": \"What's 123 * 456?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"123 * 456 = 56,088\"},\n",
    "]\n",
    "\n",
    "# Mistral 不支持 tool 角色，使用普通对话格式\n",
    "mistral_chat = mistral_tokenizer.apply_chat_template(messages_with_tools, tokenize=False)\n",
    "smol_chat = smol_tokenizer.apply_chat_template(messages_with_tools, tokenize=False)\n",
    "\n",
    "print(\"Mistral格式：\")\n",
    "print(mistral_chat)\n",
    "print(\"\\nSmolLM格式：\")\n",
    "print(smol_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23127fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant that can use tools. Available tools: calculator, weather_api<|im_end|>\n",
      "<|im_start|>user\n",
      "What's 123 * 456 and is it raining in Paris?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me help you with that.\n",
      "<tool_call>\n",
      "{\"name\": \"calculator\", \"arguments\": {\"operation\": \"multiply\", \"x\": 123, \"y\": 456}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"weather_api\", \"arguments\": {\"city\": \"Paris\", \"country\": \"France\"}}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_response>\n",
      "56088\n",
      "</tool_response>\n",
      "<tool_response>\n",
      "{'condition': 'rain', 'temperature': 15}\n",
      "</tool_response><|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qwen3_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\", trust_remote_code=True)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an AI assistant that can use tools. Available tools: calculator, weather_api\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What's 123 * 456 and is it raining in Paris?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me help you with that.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": \"call_1\",\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"calculator\",\n",
    "                    \"arguments\": '{\"operation\": \"multiply\", \"x\": 123, \"y\": 456}'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"call_2\", \n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"weather_api\",\n",
    "                    \"arguments\": '{\"city\": \"Paris\", \"country\": \"France\"}'\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\"role\": \"tool\", \"tool_call_id\": \"call_1\", \"content\": \"56088\"},\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": \"call_2\",\n",
    "        \"content\": \"{'condition': 'rain', 'temperature': 15}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "qwen3_chat = qwen3_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(qwen3_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c0d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
