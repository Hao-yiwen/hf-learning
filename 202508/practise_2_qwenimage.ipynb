{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca342cc0",
   "metadata": {},
   "source": [
    "# qwenimageå›¾ç‰‡ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoyiwen/miniconda3/envs/hflearning/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a29781c01741f4818a6567002d3fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c254701c7be45f7909dc2f1301256a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 27 files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9150caecfc4540b03a28f898ac59a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4baf5a7ef014a52abeb81813cf99610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e99202928cc451da295547deda4d99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a62d9ed79484108a577559d7fa5cf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00003-of-00004.safete(â€¦):   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee2469a2acc4132a002a156c6e886d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00004-of-00004.safete(â€¦):   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462425645b874c3581b8d15be6f3a26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00002-of-00004.safete(â€¦):   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6130de5d4c04ec8954577306ec0b898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00001-of-00004.safete(â€¦):   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382b35d16683457aa82dd46e2f0c4681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/485 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bf88da0b624d85baca4fb6ddd15eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0aa0f0f5ab441496e7979cdcdbd7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8bf84762aa4e9bb39f9c8423074277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730985377b2f4fdf91def289baecda5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6cd55bb8a743ddbb9690cf3dade998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8c2715bedf495c9da9ff8d46a3832a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/371 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb66cad049e4d31a33059fb5e65395f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(â€¦):   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984adabc1fe5457c965998ea16837070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(â€¦):   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb10bcfeb924adda707085160fc3f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(â€¦):   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948d21ec5df545d393650477e9e6b180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(â€¦):   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen-Image\"\n",
    "\n",
    "# Load the pipeline\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "positive_magic = {\n",
    "    \"en\": \", Ultra HD, 4K, cinematic composition.\", # for english prompt\n",
    "    \"zh\": \", è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾.\" # for chinese prompt\n",
    "}\n",
    "\n",
    "# Generate image\n",
    "prompt = '''A coffee shop entrance features a chalkboard sign reading \"Qwen Coffee ğŸ˜Š $2 per cup,\" with a neon light beside it displaying \"é€šä¹‰åƒé—®\". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \"Ï€â‰ˆ3.1415926-53589793-23846264-33832795-02384197\". Ultra HD, 4K, cinematic composition'''\n",
    "\n",
    "negative_prompt = \" \" # using an empty string if you do not have specific concept to remove\n",
    "\n",
    "\n",
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1140),\n",
    "    \"3:4\": (1140, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "width, height = aspect_ratios[\"16:9\"]\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=50,\n",
    "    true_cfg_scale=4.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"example.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabb609e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hflearning/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hflearning/lib/python3.10/site-packages/torchvision/_meta_registrations.py:26\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hflearning/lib/python3.10/site-packages/torchvision/_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[1;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "\n",
    "# å¦‚æœdiffuserså·²å®‰è£…\n",
    "try:\n",
    "    import diffusers\n",
    "    print(f\"Diffusers: {diffusers.__version__}\")\n",
    "except:\n",
    "    print(\"Diffusersæ— æ³•å¯¼å…¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d730eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonè·¯å¾„: /home/haoyiwen/miniconda3/envs/hflearning/bin/python\n",
      "âœ— å±æ€§é”™è¯¯: module 'torch' has no attribute '__version__'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Pythonè·¯å¾„: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ“ Torchç‰ˆæœ¬: {torch.__version__}\")\n",
    "    print(f\"âœ“ Torchä½ç½®: {torch.__file__}\")\n",
    "    \n",
    "    # æ£€æŸ¥torch.fftæ¨¡å—\n",
    "    print(f\"\\næ£€æŸ¥torch.fftæ¨¡å—:\")\n",
    "    print(f\"  torch.fft: {torch.fft}\")\n",
    "    print(f\"  å¯ç”¨å‡½æ•°: {dir(torch.fft)}\")\n",
    "    \n",
    "    # æµ‹è¯•FFTåŠŸèƒ½\n",
    "    x = torch.randn(10)\n",
    "    result = torch.fft.fft(x)\n",
    "    print(f\"âœ“ FFTåŸºæœ¬åŠŸèƒ½æ­£å¸¸\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âœ— å¯¼å…¥é”™è¯¯: {e}\")\n",
    "except AttributeError as e:\n",
    "    print(f\"âœ— å±æ€§é”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fe0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
