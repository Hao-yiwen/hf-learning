{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85625ce",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8366a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 结果 1 ---\n",
      "您好的时候,就比如果克尼夫说了。这是为了亚乌菈这样的话说不过,说不过回来的那样。 She would like to know whether there is any way to get rid of it. 可能够�\n",
      "\n",
      "--- 结果 2 ---\n",
      "您好了建设记的。您这个它说不停加吧,但是下,还是矮人矮人矮人的。他们他们还是矮人的。其中那个借力下到即使的�\n",
      "\n",
      "--- 结果 3 ---\n",
      "您好的话,这是你们们可能会有发生消贵时,但是在那样的您好的话。 But even if I had to say that this was the most impressive thing that she'd done, I think it was far from the most difficult thing that she'd done. 可能够很\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "checkpoints = \"openai-community/gpt2-medium\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoints)\n",
    "\n",
    "raw_inputs = \"您好\"\n",
    "\n",
    "inputs = tokenizer(raw_inputs, return_tensors=\"pt\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoints,     torch_dtype=torch.float16)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=100,           # 增加生成长度\n",
    "    num_return_sequences=3,   # 生成多个结果\n",
    "    temperature=0.8,          # 增加随机性\n",
    "    do_sample=True,           # 使用采样而不是贪婪搜索\n",
    "    top_p=0.9,               # nucleus sampling\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"\\n--- 结果 {i+1} ---\")\n",
    "    print(tokenizer.decode(output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7501cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8727,  389,  345,   30,  198,  198,   40, 1101,  407, 1654,  611,  345,\n",
      "          821,  257, 4336,  286,  262,  905,   11,  475,  314, 1101,  407, 1654]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc6ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who are you?\n",
      "\n",
      "I'm not sure if you're a fan of the show, but I'm not sure\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e19134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "model1 = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29b82bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22f203581714ffdad340982ae184aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c7fe4728ab43dd96bde1eecbe1a2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba20235",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a227862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ll directory_on_my_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9344df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.safetensors size: 433263448 bytes\n",
      "model.safetensors size: 413.19 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the size of model.safetensors file\n",
    "file_path = \"directory_on_my_computer/model.safetensors\"\n",
    "if os.path.exists(file_path):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"model.safetensors size: {file_size} bytes\")\n",
    "    print(f\"model.safetensors size: {file_size / (1024*1024):.2f} MB\")\n",
    "else:\n",
    "    print(\"model.safetensors file not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54482bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf543f",
   "metadata": {},
   "outputs": [],
   "source": "from huggingface_hub import login\n\n# 注意：请使用环境变量或其他安全方式管理访问令牌\n# login(\"YOUR_HF_TOKEN\")  # 替换为你的 Hugging Face 令牌"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e9bfba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2fca70bd5e464b8b6b908fb4d1556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ebb730472f4b42ab1004708176db23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901be2fb9d124641a32c024f0e53abd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  /tmp/tmpbnd_4cy5/model.safetensors    :  35%|###4      |  151MB /  433MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/yiwenX/my-awesome-model/commit/43bad26e5c4b497fc44f393024cc32ef91965693', commit_message='Upload model', commit_description='', oid='43bad26e5c4b497fc44f393024cc32ef91965693', pr_url=None, repo_url=RepoUrl('https://huggingface.co/yiwenX/my-awesome-model', endpoint='https://huggingface.co', repo_type='model', repo_id='yiwenX/my-awesome-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"my-awesome-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1e6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a474910869042ec900f633c104727ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6663ddf817914785a8af80b0dffe6b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52621cbfc4d4bfcaaf57deea28065c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543189b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,  146,  112,  182, 2503,  117, 6243,\n",
      "         1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\", return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5999e685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1731, 1132, 1128, 136, 102]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = tokenizer(\"How are you?\")\n",
    "print(encoder_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "837b08cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] How are you? [SEP]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoder_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2102021",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3e33280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4741,  0.2894,  0.0583,  ..., -0.1749,  0.6528,  0.3278],\n",
      "         [ 0.2337, -0.8369,  1.1550,  ..., -0.5131, -0.4901, -0.0559],\n",
      "         [ 0.4088, -0.3267,  0.3037,  ..., -0.6207, -0.7310,  0.7143],\n",
      "         ...,\n",
      "         [ 0.1326,  0.3779,  0.2640,  ...,  0.0186, -0.3096,  0.8506],\n",
      "         [-0.0668,  0.1708,  0.2882,  ...,  0.0910, -0.2584,  0.1871],\n",
      "         [-0.0159,  0.4975,  0.0131,  ...,  0.1539,  0.8352,  0.3783]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9585,  0.7739,  1.0000, -0.9998,  0.9988, -0.7192,  0.9999,  0.7004,\n",
      "         -0.9997, -0.9635,  0.9997,  0.9999,  0.2103, -1.0000, -0.8636, -0.9996,\n",
      "          0.9997, -0.9075, -1.0000,  0.6609,  0.5914, -1.0000,  0.7421, -0.5249,\n",
      "          0.9996,  0.1759,  0.9994,  1.0000,  0.9983,  0.5574,  0.7497, -0.9997,\n",
      "         -0.6880, -1.0000,  0.5779, -0.6658, -0.6731, -0.6448, -0.6612,  0.2597,\n",
      "         -0.9946,  0.5005, -0.4050, -0.8202, -0.2570,  0.8646,  0.6844, -0.0503,\n",
      "         -0.5871,  1.0000, -0.9998,  1.0000,  0.1859,  1.0000,  0.9999,  0.8350,\n",
      "          0.9999,  0.4877,  0.4167,  0.9622,  0.9985, -0.3559,  0.9981, -0.8171,\n",
      "         -0.6469, -0.9471,  0.2860,  0.6297, -0.8888,  0.8335,  0.9520,  0.7410,\n",
      "          0.9999, -0.9954, -0.1744, -0.9895,  0.7980, -1.0000,  0.9987,  1.0000,\n",
      "         -0.7805, -1.0000,  0.9998, -0.7240,  0.7426, -0.9937,  0.0702, -1.0000,\n",
      "          0.3162, -0.9611, -0.2151, -0.9996, -0.6297,  0.7080,  1.0000, -0.3434,\n",
      "         -0.5744,  0.7538, -0.5106,  0.9556, -0.9801, -0.5250, -0.1883,  0.6114,\n",
      "          0.2554, -0.6585, -0.9909,  0.6481, -0.8948,  0.4954,  0.9999, -1.0000,\n",
      "          0.7565,  0.4564, -0.1405,  0.6281,  0.9997, -0.4871, -0.6565,  1.0000,\n",
      "         -0.5768,  0.2315,  1.0000, -0.6326,  0.8148, -0.7488,  0.5672, -0.3872,\n",
      "          0.6013, -0.9265,  0.9414, -0.9996, -0.2832,  1.0000, -0.7189,  1.0000,\n",
      "         -1.0000,  0.1026, -1.0000,  0.8681,  0.6771, -0.2865, -0.2355,  0.8048,\n",
      "          0.9999,  0.6235,  0.2898,  0.8810, -0.5967,  0.8811,  0.9734,  0.9561,\n",
      "         -0.9993,  1.0000, -0.2074, -0.2343,  0.2209,  0.5850,  0.4690, -0.2799,\n",
      "          0.9997, -1.0000, -0.7316,  0.3529,  1.0000,  0.9995, -0.8935,  0.7487,\n",
      "          1.0000,  0.8848,  0.8801, -0.7426, -0.7321, -0.0744,  0.7669,  0.7969,\n",
      "          0.9856,  1.0000, -0.9998,  1.0000,  1.0000, -0.8351,  0.9727, -0.4756,\n",
      "         -0.9999, -0.9996, -0.9995,  0.6913, -0.9827, -0.5171, -0.6745,  0.9985,\n",
      "         -0.0781,  0.9913, -1.0000, -0.7292,  0.9992, -0.6427,  1.0000,  0.4789,\n",
      "         -1.0000,  0.5056, -0.3014,  0.9999, -0.6938,  0.9998,  0.8646,  0.6634,\n",
      "         -0.5843, -1.0000, -0.6268, -0.5679, -0.8362,  0.9928,  0.9999,  0.6098,\n",
      "         -0.5738,  0.6063,  0.4735,  1.0000, -1.0000, -0.5836,  0.9527, -0.9998,\n",
      "         -0.9999,  0.9998, -0.4841,  0.6520, -0.6817, -0.9964,  0.5483, -0.4989,\n",
      "          0.9996,  0.7657,  0.9867, -1.0000,  0.6915, -0.9973,  0.6606,  0.4528,\n",
      "          0.9149, -0.7764, -0.9984,  0.2307,  0.9993, -0.6402,  0.5384, -0.9326,\n",
      "          0.9285,  0.2411, -0.8575,  0.6830, -1.0000,  1.0000,  0.7266, -0.0022,\n",
      "          0.9999, -0.9999, -0.8493,  0.4547, -0.3376, -1.0000, -0.4795, -0.9178,\n",
      "          0.8002, -0.6714,  0.9997, -0.9997,  0.8058, -0.6693, -1.0000,  0.9968,\n",
      "         -0.7572,  1.0000, -0.1839,  0.4190,  0.9998, -0.7117, -0.9994, -1.0000,\n",
      "         -0.7593,  1.0000, -0.9998, -0.6406,  1.0000,  0.4488, -0.9938, -0.9970,\n",
      "         -1.0000, -1.0000, -0.6159,  0.7600, -0.2562,  0.9998, -0.7238, -0.4371,\n",
      "          0.9998,  1.0000, -0.4520,  0.5391,  0.5689, -0.9986, -1.0000, -0.3909,\n",
      "          0.5961, -1.0000,  1.0000, -0.9999,  1.0000, -0.3110,  0.7784,  0.9935,\n",
      "         -0.3403,  0.0597,  0.5063,  1.0000,  0.9996, -0.5078,  0.6410, -0.0700,\n",
      "          0.5006, -0.8938,  0.8760,  0.7127,  0.6527, -0.9958,  0.1282, -0.9141,\n",
      "         -0.9999, -0.0254,  0.4609,  0.9900,  0.8049,  0.9920,  0.9998, -0.5869,\n",
      "          0.7656, -0.7596, -1.0000,  0.5071,  0.7408,  0.0671,  0.3445, -0.3232,\n",
      "          0.9998, -0.9999,  1.0000, -0.5095, -0.7044,  0.4048,  1.0000, -1.0000,\n",
      "          0.5112, -0.6744,  0.3101,  0.8140,  0.9998, -0.5969, -0.5897, -0.3376,\n",
      "          0.6876,  0.9986,  0.9996, -0.3748, -0.1407,  0.4141,  0.9068,  0.9999,\n",
      "         -0.6094, -0.3087, -0.7242,  0.4259,  0.9988,  0.6036,  0.3180, -0.5756,\n",
      "          0.6272, -0.8404, -0.5570,  0.8380, -0.5999,  0.6254, -0.9999, -0.6020,\n",
      "         -0.8034,  1.0000, -0.9986, -0.7648,  0.9998, -0.5994,  0.5724,  0.9516,\n",
      "         -0.3453, -0.9996, -0.5826, -1.0000, -0.1111, -0.9235,  0.6083,  0.8571,\n",
      "          0.1284,  0.8318, -0.0486, -0.7807,  0.9731,  0.6812,  0.9996,  0.8192,\n",
      "         -0.5277, -0.6581,  0.6647,  0.7827, -0.3672,  0.9998, -0.9998,  1.0000,\n",
      "         -0.9716, -1.0000,  0.4480,  0.8583, -1.0000, -0.7592, -1.0000,  0.9997,\n",
      "         -0.0254,  0.4840,  0.1920, -1.0000, -1.0000, -0.7387, -0.6756, -0.5325,\n",
      "         -0.4658,  1.0000,  0.3067,  0.8285, -0.4847, -0.9989,  0.5700,  0.1825,\n",
      "         -0.7452, -1.0000,  0.9420,  0.0602,  0.6385,  0.6791, -0.9967,  0.7329,\n",
      "         -0.9943,  0.9124,  0.9998,  0.8487,  0.8152, -1.0000,  0.9999,  0.7631,\n",
      "          0.5757,  0.8032, -0.9996,  1.0000, -0.7398,  0.4055, -0.6098, -1.0000,\n",
      "          0.1728,  0.3710,  0.6414, -0.9996,  0.7259, -0.9994, -1.0000,  0.4546,\n",
      "         -0.0250,  1.0000,  0.9986,  0.9319, -0.7961, -0.9970,  0.6683, -1.0000,\n",
      "         -0.7063, -0.8852, -0.9998,  0.8403,  0.9999,  0.9997,  0.6328, -0.3647,\n",
      "         -0.5397,  0.8921,  0.9991,  0.9513, -0.9013,  0.6793, -0.4959, -0.9998,\n",
      "         -0.9934,  0.9998,  0.3126,  0.9996,  0.2865, -0.0504,  0.4169, -0.6656,\n",
      "         -0.2678, -1.0000, -0.9569, -0.3754, -1.0000,  1.0000, -1.0000, -0.6663,\n",
      "          0.9227, -0.4136,  0.9996,  0.5386, -1.0000, -1.0000, -0.5900, -0.6947,\n",
      "          0.9998, -0.3365,  0.6814,  0.7608,  0.9635,  1.0000, -0.1196,  0.8358,\n",
      "          0.3265,  1.0000,  0.9612, -0.9999,  0.1120, -1.0000, -0.8534,  0.9992,\n",
      "          0.9915,  0.9998,  0.3017,  1.0000, -1.0000,  1.0000, -1.0000,  0.4957,\n",
      "          1.0000, -0.9997,  0.8878, -1.0000, -0.1233, -0.8347,  0.4488, -0.7944,\n",
      "          0.9996, -1.0000, -0.9999,  0.8277,  0.0991,  0.8341, -0.1340,  0.7541,\n",
      "          0.9999,  0.4731,  0.9994, -0.5712, -0.3096,  1.0000,  0.7732,  0.4552,\n",
      "         -0.9997,  0.9997,  0.8734,  0.8282,  0.9975, -0.3310,  0.4054,  0.7961,\n",
      "         -0.9999, -0.3646, -0.9999, -0.9505, -0.5804,  0.9769,  0.4985,  0.3271,\n",
      "          0.3346, -0.9999,  0.8393, -1.0000,  0.9994,  0.1494,  0.5615, -0.7724,\n",
      "          0.8619, -0.9991,  1.0000,  1.0000, -1.0000,  0.5864,  0.9997,  0.8728,\n",
      "          0.9994, -0.9997, -0.4038, -0.5297, -0.9814,  0.9996,  0.7001, -0.5491,\n",
      "          0.9971, -0.9998,  0.8083, -0.9695, -0.4514,  0.9310, -0.9981,  0.5943,\n",
      "         -0.3572,  0.4701, -1.0000,  0.5170, -1.0000, -0.6080,  0.9993,  0.8235,\n",
      "          1.0000,  0.7644, -0.3515, -0.2803, -1.0000,  0.3180,  0.5946, -0.6105,\n",
      "          0.4440, -0.3448,  0.6340, -0.9292, -1.0000,  0.6929, -0.1909,  0.7880,\n",
      "          0.9971,  0.8057, -0.9996,  0.3166, -0.9664,  0.5763, -0.8083, -0.9999,\n",
      "          0.4956,  0.6706,  1.0000, -0.9999, -0.9910, -0.9990, -0.6724, -0.5485,\n",
      "          0.7486,  0.2872,  0.7680, -0.8737,  0.3390,  0.9999, -0.9998, -0.9999,\n",
      "          1.0000, -0.6981,  0.3446, -0.4874, -0.8011, -0.5112, -0.3231, -0.8535,\n",
      "         -0.9979, -0.6277, -1.0000, -0.6521,  0.7635, -0.9999, -0.9650, -0.7619,\n",
      "         -1.0000,  0.9998,  0.9979,  1.0000, -1.0000,  0.9890,  0.6246,  1.0000,\n",
      "          0.1453, -0.9156, -0.2174,  1.0000,  0.8911, -0.8727,  0.1214, -0.3735,\n",
      "         -0.5367, -0.8876, -0.5051,  0.1834,  0.8743, -0.9990, -1.0000,  1.0000,\n",
      "         -0.4381,  0.9995,  0.6490, -0.8129, -0.9964, -0.2728, -0.0586, -0.9956,\n",
      "         -1.0000,  0.8193, -1.0000, -0.9997,  0.6416,  0.9999, -1.0000, -0.9999,\n",
      "          0.4007, -1.0000, -0.5924, -0.1569,  0.7491, -0.9999, -0.4922, -0.8746,\n",
      "          0.9967,  0.9993, -0.9998, -0.5277,  0.2244,  1.0000,  0.6278,  0.6195,\n",
      "          0.6791, -0.0283,  0.1827, -0.9983, -0.6643, -0.9998, -0.9982,  0.9999,\n",
      "          0.9997, -1.0000, -0.9998,  0.4763, -0.7339,  0.9996, -0.9428, -1.0000,\n",
      "         -1.0000,  0.6676, -0.7983,  0.9998, -0.7800,  1.0000,  0.9799,  0.4027,\n",
      "         -0.5408,  0.8973,  0.6088,  0.7355, -0.6010,  1.0000,  0.8669,  0.9996]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2505e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}